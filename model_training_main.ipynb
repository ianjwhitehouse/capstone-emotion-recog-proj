{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.load(\"openface_and_labels_by_frame.npz\")\n",
    "X, y = xy[\"x\"], xy[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (604901, 713)\n",
      "y shape: (604901, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713,)\n"
     ]
    }
   ],
   "source": [
    "print(X[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random X min: -116.95789\n",
      "random X max: 422.15787\n",
      "random y min: 0.0\n",
      "random y max: 0.6666667\n"
     ]
    }
   ],
   "source": [
    "X_sample = X[np.random.choice(len(X))]\n",
    "y_sample = y[np.random.choice(len(y))]\n",
    "print(\"random X min:\", np.min(X_sample))\n",
    "print(\"random X max:\", np.max(X_sample))\n",
    "print(\"random y min:\", np.min(y_sample))\n",
    "print(\"random y max:\", np.max(y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x min: -34065332.0\n",
      "x max: 48234530.0\n"
     ]
    }
   ],
   "source": [
    "print(\"x min:\", np.min(X))\n",
    "print(\"x max:\", np.max(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_y(y):\n",
    "    for i in range(y.shape[1]):\n",
    "        print(\"min y, index\", i, \":\", np.min(y[:,i]))\n",
    "        print(\"max y, index\", i, \":\", np.max(y[:,i]), \"\\n\")\n",
    "\n",
    "    print(\"y min:\", np.min(y[:,4]))\n",
    "    print(\"y max:\", np.max(y))\n",
    "    print(\"y mean:\", np.mean(y))\n",
    "    print(\"y std:\", np.std(y), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min y, index 0 : -3.0\n",
      "max y, index 0 : 3.0 \n",
      "\n",
      "min y, index 1 : 0.0\n",
      "max y, index 1 : 3.0 \n",
      "\n",
      "min y, index 2 : 0.0\n",
      "max y, index 2 : 3.0 \n",
      "\n",
      "min y, index 3 : 0.0\n",
      "max y, index 3 : 3.0 \n",
      "\n",
      "min y, index 4 : 0.0\n",
      "max y, index 4 : 3.0 \n",
      "\n",
      "min y, index 5 : 0.0\n",
      "max y, index 5 : 3.0 \n",
      "\n",
      "min y, index 6 : 0.0\n",
      "max y, index 6 : 1.6666666 \n",
      "\n",
      "y min: 0.0\n",
      "y max: 3.0\n",
      "y mean: 0.17889453\n",
      "y std: 0.56088483 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_y(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: per the paper, the integral [-3, 3] for the target values, as implied above (min/max) represents sentiment, with +3 being highly positive, -3 highly negative, 0 neutral. the mean value is also consistent with the distribution shown in the paper (pp 2240 fig 2), which shows that most annotations are neutral or weakly positive (0-1). do we need to balance the classes at some point? **note that the first index (i=0) of any given target array represents this integral.\n",
    "\n",
    "The paper mentions a second integral [0,3] which measures the presence of emotion (0 = no presence, 3 = highest presence). It looks like indices 1-5 of the target arrays are of this integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.16666667, 0.33333334, 0.5       , 0.6666667 ,\n",
       "       0.8333333 , 1.        , 1.1666666 , 1.3333334 , 1.6666666 ,\n",
       "       2.        , 2.1666667 , 2.3333333 , 2.6666667 , 3.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it looks like the values are specifically sixths (1/6) between the intervals I specified above for each of the 7 labels. once I was sure of this, I went ahead and converted them to integer representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18., -16., -14., -12., -10.,  -8.,  -6.,  -4.,  -3.,  -2.,  -1.,\n",
       "         0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  18.], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded = y * 6\n",
    "np.unique(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = np.round(y_encoded).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min y, index 0 : -18\n",
      "max y, index 0 : 18 \n",
      "\n",
      "min y, index 1 : 0\n",
      "max y, index 1 : 18 \n",
      "\n",
      "min y, index 2 : 0\n",
      "max y, index 2 : 18 \n",
      "\n",
      "min y, index 3 : 0\n",
      "max y, index 3 : 18 \n",
      "\n",
      "min y, index 4 : 0\n",
      "max y, index 4 : 18 \n",
      "\n",
      "min y, index 5 : 0\n",
      "max y, index 5 : 18 \n",
      "\n",
      "min y, index 6 : 0\n",
      "max y, index 6 : 10 \n",
      "\n",
      "y min: 0\n",
      "y max: 18\n",
      "y mean: 1.0733673774716854\n",
      "y std: 3.365308890115125 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_y(y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide later exactly how much of the data ought to be used, but for the sake of testing things for now, I've truncated the dataset to something more manageable from a time perspective (sample a number (n_samples * m_percent) of random indices and extract those indices from the features/targets). I can perform a larger-in-scale training session over break on my GPU desktop (hopefully without interruption due to hardware limitations) once we're satisfied with the model parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_data(X, y, n_samples):\n",
    "    random_i = np.random.choice(len(X), size = n_samples)\n",
    "    X_trunc = X[random_i]\n",
    "    y_trunc = y[random_i]\n",
    "    return X_trunc, y_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_truncated, y_truncated_emotion = truncate_data(X, y_encoded[:,1:], int(X.shape[0] * 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_truncated_sentiment = truncate_data(X, y_encoded[:,0], int(X.shape[0] * 0.5))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 241960\n",
      "Test: 60490\n",
      "y shape: (241960, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_truncated, y_truncated_emotion, test_size = 0.2)\n",
    "\n",
    "print(\"Train:\", X_train.shape[0])\n",
    "print(\"Test:\", X_test.shape[0])\n",
    "print(\"y shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting presence of emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "emotion_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
    "  tf.keras.layers.Dense(712, activation='relu'),\n",
    "  tf.keras.layers.Dense(712, activation='relu'),\n",
    "  tf.keras.layers.Dense(356, activation='relu'),\n",
    "  tf.keras.layers.Dense(178, activation='relu'),\n",
    "  tf.keras.layers.Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.compile(optimizer='adam',\n",
    "  loss=mse_loss,\n",
    "  metrics=tf.keras.metrics.Precision())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6049/6049 [==============================] - 31s 5ms/step - loss: 5.9850 - precision_3: 0.5494 - val_loss: 5.9481 - val_precision_3: 0.5647\n",
      "Epoch 2/10\n",
      "6049/6049 [==============================] - 31s 5ms/step - loss: 5.9592 - precision_3: 0.5622 - val_loss: 5.9482 - val_precision_3: 0.5647\n",
      "Epoch 3/10\n",
      "6049/6049 [==============================] - 30s 5ms/step - loss: 5.9592 - precision_3: 0.5622 - val_loss: 5.9482 - val_precision_3: 0.5647\n",
      "Epoch 4/10\n",
      "6049/6049 [==============================] - 30s 5ms/step - loss: 5.9592 - precision_3: 0.5622 - val_loss: 5.9482 - val_precision_3: 0.5647\n",
      "Epoch 5/10\n",
      "6049/6049 [==============================] - 32s 5ms/step - loss: 5.9592 - precision_3: 0.5622 - val_loss: 5.9482 - val_precision_3: 0.5647\n",
      "Epoch 6/10\n",
      "6049/6049 [==============================] - 30s 5ms/step - loss: 5.9592 - precision_3: 0.5622 - val_loss: 5.9482 - val_precision_3: 0.5647\n",
      "Epoch 7/10\n",
      "6049/6049 [==============================] - 32s 5ms/step - loss: 5.9592 - precision_3: 0.5622 - val_loss: 5.9482 - val_precision_3: 0.5647\n",
      "Epoch 8/10\n",
      "6049/6049 [==============================] - 31s 5ms/step - loss: 5.9592 - precision_3: 0.5622 - val_loss: 5.9482 - val_precision_3: 0.5647\n",
      "Epoch 9/10\n",
      "6049/6049 [==============================] - 32s 5ms/step - loss: 5.9592 - precision_3: 0.5622 - val_loss: 5.9482 - val_precision_3: 0.5647\n",
      "Epoch 10/10\n",
      "6049/6049 [==============================] - 30s 5ms/step - loss: 5.9592 - precision_3: 0.5622 - val_loss: 5.9482 - val_precision_3: 0.5647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28427033850>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_model.fit(X_train, y_train, epochs=10, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.save_weights(\"em1/em1_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891/1891 [==============================] - 3s 2ms/step - loss: 5.9241 - precision_3: 0.5599\n",
      "Loss: 5.924108505249023\n",
      "Accuracy 0.5599437952041626\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = emotion_model.evaluate(X_test, y_test)\n",
    "print(test_loss)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 241960\n",
      "Test: 60490\n",
      "y shape: (241960,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_truncated, y_truncated_sentiment, test_size = 0.2)\n",
    "\n",
    "print(\"Train:\", X_train.shape[0])\n",
    "print(\"Test:\", X_test.shape[0])\n",
    "print(\"y shape:\", y_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
